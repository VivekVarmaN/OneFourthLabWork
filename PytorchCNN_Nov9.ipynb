{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchCNN_Nov9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS8jKuZIUDfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYcjHQVjVYf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4cbdaf66-c72b-4087-ddb1-cc1b4e907a6a"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train= True, download = True, transform = transforms.ToTensor())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 27858132.39it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_j4f_13WSNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Us05U7TWlY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh1RVy9_XMTp",
        "colab_type": "text"
      },
      "source": [
        "## LeNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1CzmuIW7-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNET(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNET,self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),  # 3 -> depth in that layer , 6 -> number of filter/kernels , 5 -> kernel size\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2, stride = 2),\n",
        "            nn.Conv2d(6, 16, 5),  # 6 -> depth of that layer, 16-> number of filters,  5-> kernel size\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2, stride = 2)\n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(400,120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84,10)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        #print(x.shape)\n",
        "        x = self.cnn_model(x)\n",
        "        #print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #print(x.shape)\n",
        "        x = self.fc_model(x)\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO3MoG23gK8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "de49803e-1af6-4927-f6a5-f122bce2eba5"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "print(images[1].shape)\n",
        "print(labels[1].item())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([3, 32, 32])\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgqOJ0lygNs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = LeNET()\n",
        "out = net(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NoavtyTacZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1357aafe-9607-4a1f-8da5-3ef5275bf547"
      },
      "source": [
        "batch_size = 128\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmUU_dndazLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        outputs = net(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXRmw54HbTMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = LeNET()\n",
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgzF4nNUbaey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "325e603b-582e-491c-920d-7176cc09b4a8"
      },
      "source": [
        "\n",
        "loss_arr = []\n",
        "loss_epoch_arr = []\n",
        "max_epochs = 16\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        loss_arr.append(loss.item())\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch, max_epochs, evaluation(testloader), evaluation(trainloader)))\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/16, Test acc: 39.44, Train acc: 39.41\n",
            "Epoch: 1/16, Test acc: 43.15, Train acc: 43.48\n",
            "Epoch: 2/16, Test acc: 46.43, Train acc: 46.57\n",
            "Epoch: 3/16, Test acc: 48.48, Train acc: 49.15\n",
            "Epoch: 4/16, Test acc: 49.47, Train acc: 50.10\n",
            "Epoch: 5/16, Test acc: 49.91, Train acc: 51.23\n",
            "Epoch: 6/16, Test acc: 52.34, Train acc: 53.51\n",
            "Epoch: 7/16, Test acc: 52.76, Train acc: 53.96\n",
            "Epoch: 8/16, Test acc: 52.52, Train acc: 54.63\n",
            "Epoch: 9/16, Test acc: 51.18, Train acc: 53.69\n",
            "Epoch: 10/16, Test acc: 54.51, Train acc: 56.75\n",
            "Epoch: 11/16, Test acc: 54.38, Train acc: 57.17\n",
            "Epoch: 12/16, Test acc: 54.39, Train acc: 57.69\n",
            "Epoch: 13/16, Test acc: 54.36, Train acc: 57.34\n",
            "Epoch: 14/16, Test acc: 55.57, Train acc: 59.36\n",
            "Epoch: 15/16, Test acc: 53.83, Train acc: 57.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h2jA3KWkNqj",
        "colab_type": "text"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBMDHySskM_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59906d93-3ebe-4a8f-afb7-676deb45344d"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcIu3Zm6brnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net1(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIXeIPb9kX9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net1 = LeNET().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIu6ehyPka41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "77141210-1663-42d3-ec50-6e4451735ad2"
      },
      "source": [
        "%%time\n",
        "loss_arr = []\n",
        "loss_epoch_arr = []\n",
        "max_epochs = 16\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = net1(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        loss_arr.append(loss.item())\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "    print('Epoch: %d/%d' % (epoch, max_epochs))    \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch, max_epochs, evaluation(testloader), evaluation(trainloader)))\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()\n",
        "        \n",
        "    "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/16\n",
            "Epoch: 0/16, Test acc: 10.00, Train acc: 10.00\n",
            "Epoch: 1/16\n",
            "Epoch: 1/16, Test acc: 10.00, Train acc: 10.00\n",
            "Epoch: 2/16\n",
            "Epoch: 2/16, Test acc: 10.00, Train acc: 10.00\n",
            "Epoch: 3/16\n",
            "Epoch: 3/16, Test acc: 10.00, Train acc: 10.00\n",
            "Epoch: 4/16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-ff4dee50821e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss_arr = []\\nloss_epoch_arr = []\\nmax_epochs = 16\\n\\nfor epoch in range(max_epochs):\\n\\n    for i, data in enumerate(trainloader, 0):\\n\\n        inputs, labels = data\\n        inputs, labels = inputs.to(device), labels.to(device)\\n\\n        opt.zero_grad()\\n\\n        outputs = net1(inputs)\\n        loss = loss_fn(outputs, labels)\\n        loss.backward()\\n        opt.step()\\n        loss_arr.append(loss.item())\\n        \\n    loss_epoch_arr.append(loss.item())\\n    print('Epoch: %d/%d' % (epoch, max_epochs))    \\n    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch, max_epochs, evaluation(testloader), evaluation(trainloader)))\\n    \\n    \\nplt.plot(loss_epoch_arr)\\nplt.show()\\n        \\n    \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-ea4a6f155478>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2436\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2438\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2389\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2324\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R24Y4qUOlDuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}